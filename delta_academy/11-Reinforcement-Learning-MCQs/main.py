from ex1_checks import (
    check_definition_1,
    check_definition_2,
    check_definition_3,
    check_definition_4,
)


### 4.1. What type of problems are Reinforcement Learning problems? ###

# Don't edit this
option_a = "Any problem which is in discrete time"
option_b = "Problems with computational solutions"
option_c = "Classification problems"
option_d = "Sequential decision-making problems"

# TODO: Fill in your answer here
check_definition_1(your_answer=...)

###------------------------------------------------------------###


### 4.2. What is the meaning of the term "discrete time process"? ###

# Don't edit this
option_a = "A process where you make decisions throughout time"
option_b = "A process in which time is modelled with discrete steps"
option_c = "A process in which time is modelled as a continuous quantity"
option_d = "A process where there is no time dimension"

# TODO: Fill in your answer here
check_definition_2(your_answer=...)

###------------------------------------------------------------###


### 4.3. What are the 3 key elements of a Markov Decision Process? ###

# Don't edit this
option_a = "States, actions & rewards"
option_b = "Neural networks, chess game & oil refinery"
option_c = "Computation, agent & environment"
option_d = "Markov, Decision & Process"

# TODO: Fill in your answer here
check_definition_3(your_answer=...)


###------------------------------------------------------------###

### 4.4. What are you trying to maximise in an MDP? ###

# Don't edit this
option_a = "The reward in the next timestep"
option_b = "The number of actions taken"
option_c = "The size of the environment your agent is interacting with"
option_d = "The sum of future rewards"

# TODO: Fill in your answer here
check_definition_4(your_answer=...)
